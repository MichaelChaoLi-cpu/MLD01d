{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Check Explanation of the relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import yaml\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ExplainResult\n",
    "import Modelling\n",
    "import SettingForFeatures\n",
    "import TestingTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(SettingForFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_serializable(obj):\n",
    "    if hasattr(obj, 'item'):\n",
    "        return obj.item()\n",
    "    if hasattr(obj, 'tolist'):\n",
    "        return obj.tolist()\n",
    "    raise TypeError(f\"Type not serializable: {type(obj)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_pdp_self_defined(\n",
    "    var: str,\n",
    "    X: pd.DataFrame,\n",
    "    model_list: list,\n",
    "    range_boundary=(0.05, 0.95),\n",
    "    stripe: float = 0.2\n",
    ") -> tuple:\n",
    "    # Determine the grid boundaries based on the specified quantiles\n",
    "    low_b = range_boundary[0]\n",
    "    up_b = range_boundary[1]\n",
    "    \n",
    "    # Generate the discrete grid of feature values\n",
    "    potenital_values = np.arange(low_b, up_b, stripe)\n",
    "    X_adjust = X.copy()\n",
    "    \n",
    "    pdp_list = []\n",
    "    \n",
    "    # Iterate through each model in the ensemble/list\n",
    "    for model in model_list:\n",
    "        pdp = np.full_like(potenital_values, fill_value=np.nan)\n",
    "        \n",
    "        # Iterate through each grid point (potential value)\n",
    "        for idx, potenital_value in enumerate(potenital_values):\n",
    "            # 1. Substitute the feature column with the current fixed value\n",
    "            X_adjust[var] = potenital_value.astype(float)\n",
    "            \n",
    "            # 2. Predict the outcome for the entire adjusted dataset\n",
    "            y_pred = model.predict_proba(X_adjust)[:,1]\n",
    "            \n",
    "            # 3. Calculate the partial dependence (average prediction)\n",
    "            pdp[idx] = np.mean(y_pred)\n",
    "        \n",
    "        pdp_list.append(pdp)\n",
    "\n",
    "    pdp_array = np.array(pdp_list)\n",
    "\n",
    "    return potenital_values, pdp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patheffects as path_effects\n",
    "\n",
    "def plot_spatial_difference(\n",
    "    map_df: gpd.GeoDataFrame,\n",
    "    save_address: str,\n",
    "    col: str = \"difference\",\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    title: str = \"Difference\",\n",
    "    annotate: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single spatial map for one column (default: 'difference').\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    map_df : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing geometry and the target column.\n",
    "    save_address : str\n",
    "        Output path for saving the figure (e.g., 'out.png').\n",
    "    col : str, default='difference'\n",
    "        Column name to plot.\n",
    "    vmin, vmax : float or None\n",
    "        Color scale bounds. If None, use data min/max.\n",
    "    title : str, default='Difference'\n",
    "        Figure title.\n",
    "    annotate : bool, default=True\n",
    "        Whether to annotate each polygon with its index.\n",
    "    \"\"\"\n",
    "    if col not in map_df.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in map_df.columns: {list(map_df.columns)}\")\n",
    "\n",
    "    # Infer vmin/vmax if not provided\n",
    "    data = map_df[col]\n",
    "    if vmin is None:\n",
    "        vmin = float(data.min())\n",
    "    if vmax is None:\n",
    "        vmax = float(data.max())\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "    cmap = plt.cm.RdYlBu_r\n",
    "\n",
    "    map_df.plot(\n",
    "        column=col,\n",
    "        cmap=cmap,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.4,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        alpha=0.8,\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # Optional annotation\n",
    "    for i, row in map_df.iterrows():\n",
    "        geom = row.geometry\n",
    "        if geom is not None and not geom.is_empty:\n",
    "            cx, cy = geom.centroid.x, geom.centroid.y\n",
    "            ax.text(cx, cy, f\"{i[0]}\\n{i[1]}\", fontsize=7, ha='center', va='center').set_path_effects([\n",
    "                path_effects.Stroke(linewidth=2.5, foreground='white'),\n",
    "                path_effects.Normal()\n",
    "            ])\n",
    "\n",
    "    # Colorbar\n",
    "    sm = mpl.cm.ScalarMappable(\n",
    "        norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax),\n",
    "        cmap=cmap\n",
    "    )\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, ax=ax, fraction=0.035, pad=0.02)\n",
    "    cbar.ax.tick_params(labelsize=9)\n",
    "\n",
    "    # Style\n",
    "    ax.set_title(title, fontsize=11, loc=\"left\")\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.grid(True, linestyle=\"-\", alpha=0.4)\n",
    "    ax.axis(\"on\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_address, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Map saved to: {save_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir(os.getenv(\"PROJECT_ROOT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = SettingForFeatures.data_load_combine_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "always_inputs = SettingForFeatures.return_input_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_variables = SettingForFeatures.return_output_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = SettingForFeatures.load_spatial_data()\n",
    "map_df.columns = ['EcoBelt', \"Province\", 'geometry']\n",
    "\n",
    "# Fix inconsistent province name\n",
    "map_df.loc[map_df['Province'] == 'Sudur Pashchim', 'Province'] = 'Sudurpashchim'\n",
    "# Set multi-index with Province and EcoBelt\n",
    "map_df = map_df.set_index(['Province', 'EcoBelt'])\n",
    "\n",
    "loc_df = all_data[['Prov', 'EcoBelt']]\n",
    "loc_df.columns = ['Province', 'EcoBelt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = loc_df.replace('Sudurpaschim', 'Sudurpashchim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Check PDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Health indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aim_variable in aim_variables:\n",
    "    print(aim_variable)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./{aim_variable}_params.yaml\", \"r\") as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_variable = aim_variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Modelling.prepare_data(\n",
    "    all_data = all_data,\n",
    "    always_inputs = always_inputs,\n",
    "    aim_variable = aim_variable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = Modelling.get_clsmodel_list(\n",
    "    X, y,\n",
    "    n_splits = n_splits,\n",
    "    params = params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'HeardClimate_Dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the discrete grid of feature values\n",
    "potenital_values = [0, 1]\n",
    "X_adjust = X.copy()\n",
    "\n",
    "pdp_list = []\n",
    "\n",
    "y_df = np.full((X_adjust.shape[0], len(model_list), len(potenital_values)), fill_value = np.nan)\n",
    "\n",
    "# Iterate through each model in the ensemble/list\n",
    "for model_idx, model in enumerate(model_list):\n",
    "    pdp = np.full_like(potenital_values, fill_value=np.nan)\n",
    "    \n",
    "    # Iterate through each grid point (potential value)\n",
    "    for idx, potenital_value in enumerate(potenital_values):\n",
    "        # 1. Substitute the feature column with the current fixed value\n",
    "        X_adjust[var] =  potenital_value\n",
    "        \n",
    "        # 2. Predict the outcome for the entire adjusted dataset\n",
    "        y_pred = model.predict_proba(X_adjust)[:,1]\n",
    "        \n",
    "        # 3. Calculate the partial dependence (average prediction)\n",
    "        y_df[:, model_idx, idx] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"results\", f\"health_prediction_of_{var}.npy\"), y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(y_df, axis = 1)[:,1] - np.mean(y_df, axis = 1)[:,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['negative_health_proba', 'positive_health_proba']] = np.mean(y_df, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_output = X[['negative_health_proba', 'positive_health_proba']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_output = X_output.merge(loc_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_output['difference'] = X_output['positive_health_proba'] - X_output['negative_health_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_output_region = X_output.groupby(['Province', 'EcoBelt']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = map_df.merge(X_output_region, on = ['Province', 'EcoBelt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = map_df.set_index(['Province', 'EcoBelt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spatial_difference(map_df, \"figures/difference_map.png\", col=\"difference\", title=\"Spatial Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
