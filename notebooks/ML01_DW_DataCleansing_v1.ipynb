{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Dataset 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls PrivateData/Climate-2016/Data/Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HhLevel = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/HhldLevel_KeyVariable.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HhLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in [\"RespSex\", \"RespAge\", \"RespEdu\", \"Quintl\", \"CZONE\"]:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_HhLevel[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HhLevel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_HhLevel[['PSU', 'HHLD', 'Quintl', 'CZONE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PSULevel = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/PSULevel_KeyVariable.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PSULevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PSULevel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['Dist', 'UrbRur71', 'Strata', 'EcoBelt', 'Comb_Vuln', 'Comb_Risk', 'Comb_Adap']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_PSULevel[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_PSULevel['Dist'].unique().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PSULevel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District â†’ Province mapping (for the districts you listed)\n",
    "district_to_province = {\n",
    "    # Province 1 (Koshi)\n",
    "    'Taplejung': 'Koshi',\n",
    "    'Panchthar': 'Koshi',\n",
    "    'Morang': 'Koshi',\n",
    "    'Dhankuta': 'Koshi',\n",
    "\n",
    "    # Province 2 (Madhesh)\n",
    "    'Saptari': 'Madhesh',\n",
    "    'Dhanusa': 'Madhesh',\n",
    "    'Rautahat': 'Madhesh',\n",
    "\n",
    "    # Province 3 (Bagmati)\n",
    "    'Khotang': 'Bagmati',\n",
    "    'Ramechhap': 'Bagmati',\n",
    "    'Dolakha': 'Bagmati',\n",
    "    'Kathmandu': 'Bagmati',\n",
    "    'Dhading': 'Bagmati',\n",
    "\n",
    "    # Province 4 (Gandaki)\n",
    "    'Tanahu': 'Gandaki',\n",
    "    'Kaski': 'Gandaki',\n",
    "    'Mustang': 'Gandaki',\n",
    "    'Baglung': 'Gandaki',\n",
    "\n",
    "    # Province 5 (Lumbini)\n",
    "    'Palpa': 'Lumbini',\n",
    "    'Rupandehi': 'Lumbini',\n",
    "    'Pyuthan': 'Lumbini',\n",
    "    'Dang': 'Lumbini',\n",
    "\n",
    "    # Province 6 (Karnali)\n",
    "    'Salyan': 'Karnali',\n",
    "    'Jumla': 'Karnali',\n",
    "    'Kalikot': 'Karnali',\n",
    "\n",
    "    # Province 7 (Sudurpaschim)\n",
    "    'Bajura': 'Sudurpaschim',\n",
    "    'Achham': 'Sudurpaschim',\n",
    "    'Kailali': 'Sudurpaschim',\n",
    "}\n",
    "\n",
    "# Example usage in pandas:\n",
    "df_PSULevel['Prov'] = df_PSULevel['Dist'].map(district_to_province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_PSULevel[['PSU', 'Dist', 'UrbRur71', 'Strata', 'EcoBelt', 'Prov']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = 'PSU', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept['Rural_Dummy'] = np.where(df_kept['UrbRur71'] == 'Rural', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Data Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### Section 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S01.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'A07SEX', 'A07AGE', 'A08SEX', 'A08AGE', 'A11', 'A12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = ['PSU', 'HHLD', 'HeadHH_Female', 'HeadHH_Age',\n",
    "                  'Respon_Female', 'Respon_Age', 'Edu', 'LivingYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.loc[:, 'HeadHH_Female'] = df_read.loc[:, 'HeadHH_Female'] - 1\n",
    "df_read.loc[:, 'Respon_Female'] = df_read.loc[:, 'Respon_Female'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "df_read[\"Respon_Age\"].hist(bins=17, edgecolor=\"black\")\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read.assign(\n",
    "    Edu_UnderSLC     = np.where(df_read[\"Edu\"] < 12, 1, 0),\n",
    "    Edu_Certificate  = np.where(df_read[\"Edu\"] == 12, 1, 0),\n",
    "    Edu_Bachelor     = np.where(df_read[\"Edu\"] == 13, 1, 0),\n",
    "    Edu_Master       = np.where(df_read[\"Edu\"] == 14, 1, 0),\n",
    "    Edu_PhD          = np.where(df_read[\"Edu\"] == 15, 1, 0),\n",
    "    Edu_Literal      = np.where(df_read[\"Edu\"] == 16, 1, 0),\n",
    "    Edu_Illiterate   = np.where(df_read[\"Edu\"] == 17, 1, 0)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "df_read[\"Edu\"].hist(bins=17, edgecolor=\"black\")\n",
    "plt.xlabel(\"Education Code\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(range(1, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_year_map = {\n",
    "    1: 1,  2: 2,  3: 3,  4: 4,  5: 5,  6: 6,  7: 7,  8: 8,  9: 9, 10: 10, 11: 11,\n",
    "    12: 12,      # Certificate level\n",
    "    13: 16,      # Bachelor\n",
    "    14: 18,      # Master\n",
    "    15: 21,      # PhD\n",
    "    16: 0,       # Literal\n",
    "    17: 0        # Illiterate\n",
    "}\n",
    "\n",
    "df_read[\"Edu_year\"] = df_read[\"Edu\"].map(edu_year_map).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = df_read.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_01[['PSU', 'HHLD', 'HeadHH_Female', 'HeadHH_Age', 'Respon_Female',\n",
    "       'Respon_Age', 'LivingYear', 'Edu_UnderSLC', 'Edu_Certificate',\n",
    "       'Edu_Bachelor', 'Edu_Master', 'Edu_PhD', 'Edu_Literal',\n",
    "       'Edu_Illiterate', \"Edu_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "#### Section 02-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S02_1.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['B09OCC']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S02_1.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['B09OCC']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Female_Ratio'] = df_read['B05SEX'] - 1\n",
    "df_read['U18_Ratio'] = np.where(df_read[\"B06AGE\"] < 18, 1, 0)\n",
    "df_read['A65_Ratio'] = np.where(df_read[\"B06AGE\"] >= 65, 1, 0)\n",
    "\n",
    "df_read[\"B07EDU\"] = df_read[\"B07EDU\"].fillna(17)\n",
    "df_read['Edu12_Ratio'] = np.where((df_read[\"B07EDU\"] >= 12)&(df_read[\"B07EDU\"] < 16), 1, 0)\n",
    "df_read['Literal_Ratio'] = np.where((df_read[\"B07EDU\"] >= 12)&(df_read[\"B07EDU\"] < 17), 1, 0)\n",
    "\n",
    "df_read[\"B09OCC\"] = df_read[\"B09OCC\"].fillna(7).astype(int)\n",
    "df_occ_dummies = pd.get_dummies(df_read[\"B09OCC\"], prefix=\"OCC\").astype(int)\n",
    "df_occ_dummies.columns = ['Occ_Agri', 'Occ_Wage', 'Occ_NonAgriBus', \n",
    "                          'Occ_Household', 'Occ_Stu', 'Occ_Hunting',  \n",
    "                          'Occ_NoJob', 'Occ_Uable']\n",
    "df_read = pd.concat([df_read, df_occ_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'Female_Ratio', 'U18_Ratio', 'A65_Ratio',\n",
    "       'Edu12_Ratio', 'Literal_Ratio', 'Occ_Agri', 'Occ_Wage',\n",
    "       'Occ_NonAgriBus', 'Occ_Household', 'Occ_Stu', 'Occ_Hunting',\n",
    "       'Occ_NoJob', 'Occ_Uable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_read.groupby(['PSU', 'HHLD']).count().reset_index()['B02SN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_ratio = df_select.groupby(['PSU', 'HHLD']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_ratio['Household_memberNum'] = df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select_ratio, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### Section 02-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S02_2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['B12A', 'B12B', 'B12C', 'B13A', 'B13B', 'B13C']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['B17A', 'B17B', 'B17C', 'B17D', 'B17E', 'B17F', 'B17G', 'B17H', 'B17I', 'B17J', 'B17K', 'B17L']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S02_2.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['B17A', 'B17B', 'B17C', 'B17D', 'B17E', 'B17F', 'B17G', 'B17H', 'B17I', 'B17J', 'B17K', 'B17L']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['B17A','B17B','B17C','B17D','B17E','B17F','B17G','B17H','B17I','B17J','B17K','B17L']\n",
    "\n",
    "df_read[\"Radio_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"TV_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Cable_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"PC_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Net_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Phone_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Mobile_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Motorbike_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Car_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Bike_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"OtherVehi_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)\n",
    "df_read[\"Refrige_dummy\"] = (df_read[cols] == 1).any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'B10', 'B11', 'B12A', 'B12B',\n",
    "        'B12C', 'B13A', 'B13B', 'B13C', 'B14', 'B15', 'B16A', 'B16B', 'B16C',\n",
    "         'B18', 'C01', 'Radio_dummy', 'TV_dummy',\n",
    "       'Cable_dummy', 'PC_dummy', 'Net_dummy', 'Phone_dummy', 'Mobile_dummy',\n",
    "       'Motorbike_dummy', 'Car_dummy', 'Bike_dummy', 'OtherVehi_dummy',\n",
    "       'Refrige_dummy']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.columns = ['PSU', 'HHLD', 'Own_Resid', 'Resid_Type', 'WaterS1', 'WaterS2',\n",
    "        'WaterS3', 'CookFuelS1', 'CookFuelS2', 'CookFuelS3', 'LightEnergy', 'Toilet', 'IncomeS1', 'IncomeS2', 'IncomeS3',\n",
    "         'Remittance_dummy', 'Have_AgriLand', 'Radio_dummy', 'TV_dummy',\n",
    "       'Cable_dummy', 'PC_dummy', 'Net_dummy', 'Phone_dummy', 'Mobile_dummy',\n",
    "       'Motorbike_dummy', 'Car_dummy', 'Bike_dummy', 'OtherVehi_dummy',\n",
    "       'Refrige_dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select['Remittance_dummy'] = (df_select['Remittance_dummy'] - 2).abs()\n",
    "df_select['Have_AgriLand'] = (df_select['Have_AgriLand'] - 2).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "#### Section 03 - Complicated Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S03.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "#### Section 04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "**Yes is Yes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S04.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['HouseHead_AgriExpYear'] = df_read[\"D01\"]\n",
    "df_read['SavingMembership'] = np.where(df_read[\"D02\"] == 1, 1, 0)\n",
    "df_read['RegularSaving'] = np.where(df_read[\"D03\"] == 1, 1, 0)\n",
    "df_read['OrgMembership'] = np.where(df_read[\"D04\"] == 1, 1, 0)\n",
    "df_read['AgriSupport'] = np.where(df_read[\"D05\"] == 1, 1, 0)\n",
    "df_read['Dist_Road'] = df_read[\"D06\"]\n",
    "df_read['Dist_HealthCenter'] = df_read[\"D07\"]\n",
    "df_read['Dist_SecondarySchool'] = df_read[\"D08\"]\n",
    "df_read['Dist_Market'] = df_read[\"D09\"]\n",
    "df_read['Dist_AgriSupport'] = df_read[\"D10\"]\n",
    "df_read['FramMechan'] = np.where(df_read[\"D11\"] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'HouseHead_AgriExpYear', 'SavingMembership',\n",
    "                        'RegularSaving', 'OrgMembership', 'AgriSupport', 'Dist_Road',\n",
    "                        'Dist_HealthCenter', 'Dist_SecondarySchool', 'Dist_Market',\n",
    "                        'Dist_AgriSupport', 'FramMechan']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_select.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "#### Section 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S05.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['TotalIncome'] = df_read[['E01', 'E02', 'E03', 'E04', 'E05']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = ['PSU', 'HHLD', 'CropIncome', 'LivestockIncome', 'OtherAgriIncome', 'NonAgriIncome', 'BusiIncome', 'TotalIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "#### Section 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S06.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['F01', 'F02', 'F03', 'F04A', 'F04B', 'F04C', 'F05A',\n",
    "       'F05B', 'F05C', 'F05D', 'F05E', 'F06', 'F07', 'F09', 'F10']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['HeardClimate_Dummy'] = np.where(df_read['F01'] == 'Yes', 1, 0)\n",
    "df_read['ClimateChanged_Dummy'] = np.where(df_read['F03'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "f02_dummies = pd.get_dummies(df_read[\"F02\"], prefix=\"ClimateInfo\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "f02_dummies.columns = [name[:17] for name in f02_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f02_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04a_dummies = pd.get_dummies(df_read[\"F04A\"], prefix=\"ClimateReasonA\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04a_dummies.columns = [name[:20] for name in f04a_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f04a_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04b_dummies = pd.get_dummies(df_read[\"F04B\"], prefix=\"ClimateReasonB\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04b_dummies.columns = [name[:20] for name in f04b_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f04b_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04c_dummies = pd.get_dummies(df_read[\"F04C\"], prefix=\"ClimateReasonC\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04c_dummies.columns = [name[:20] for name in f04c_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f04c_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['SummerTemp_IncreaseDummy'] = np.where(df_read['F06'] == 'Increase', 1, 0)\n",
    "df_read['SummerTemp_DecreaseDummy'] = np.where(df_read['F06'] == 'Decrease', 1, 0)\n",
    "df_read['WinterTemp_IncreaseDummy'] = np.where(df_read['F07'] == 'Increase', 1, 0)\n",
    "df_read['WinterTemp_DecreaseDummy'] = np.where(df_read['F07'] == 'Decrease', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['MonsoonPreci_IncreaseDummy'] = np.where(df_read['F09'] == 'Increase', 1, 0)\n",
    "df_read['MonsoonPreci_DecreaseDummy'] = np.where(df_read['F09'] == 'Decrease', 1, 0)\n",
    "df_read['WinterPreci_IncreaseDummy'] = np.where(df_read['F10'] == 'Increase', 1, 0)\n",
    "df_read['WinterPreci_DecreaseDummy'] = np.where(df_read['F10'] == 'Decrease', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.replace( '\\'' ,'x') for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'HeardClimate_Dummy', 'ClimateChanged_Dummy', 'ClimateInfo_Radio',\n",
    "       'ClimateInfo_Telev', 'ClimateInfo_News ', 'ClimateInfo_Aware',\n",
    "       'ClimateInfo_Local', 'ClimateInfo_Neigh', 'ClimateInfo_Famil',\n",
    "       'ClimateInfo_Other', 'ClimateReasonA_Defor', 'ClimateReasonA_Natur',\n",
    "       'ClimateReasonA_Indus', 'ClimateReasonA_Urban', 'ClimateReasonA_Human',\n",
    "       'ClimateReasonA_Godxs', 'ClimateReasonA_Earth', 'ClimateReasonA_Other',\n",
    "       'ClimateReasonA_Donxt', 'ClimateReasonB_Defor', 'ClimateReasonB_Natur',\n",
    "       'ClimateReasonB_Indus', 'ClimateReasonB_Urban', 'ClimateReasonB_Human',\n",
    "       'ClimateReasonB_Godxs', 'ClimateReasonB_Earth', 'ClimateReasonB_Other',\n",
    "       'ClimateReasonC_Defor', 'ClimateReasonC_Natur', 'ClimateReasonC_Indus',\n",
    "       'ClimateReasonC_Urban', 'ClimateReasonC_Human', 'ClimateReasonC_Godxs',\n",
    "       'ClimateReasonC_Earth', 'ClimateReasonC_Other',\n",
    "       'SummerTemp_IncreaseDummy', 'SummerTemp_DecreaseDummy',\n",
    "       'WinterTemp_IncreaseDummy', 'WinterTemp_DecreaseDummy',\n",
    "       'MonsoonPreci_IncreaseDummy', 'MonsoonPreci_DecreaseDummy',\n",
    "       'WinterPreci_IncreaseDummy', 'WinterPreci_DecreaseDummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "#### Section 06-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S06_4.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['F14', 'F15', 'F16']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['ExpDummy'] = np.where(df_read['F14'] == 1, 1, 0)\n",
    "df_read['ExpIncreaseDummy'] = np.where(df_read['F15'] == 1, 1, 0)\n",
    "df_read['ExpDecreaseDummy'] = np.where(df_read['F15'] == 2, 1, 0)\n",
    "df_read['Impact'] = df_read['F15'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"F12CODE\", \n",
    "           values=[\"ExpDummy\", 'ExpIncreaseDummy', 'ExpDecreaseDummy', 'Impact'])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    1: \"DR\",\n",
    "    2: \"FF\",\n",
    "    3: \"FS\",\n",
    "    4: \"FL\",\n",
    "    5: \"IN\",\n",
    "    6: \"WS\",\n",
    "    7 :\"TS\",\n",
    "    8: \"HS\",\n",
    "    9: \"HR\",\n",
    "    10: \"SR\",\n",
    "    11: \"SE\",\n",
    "    12: \"LS\",\n",
    "    13: \"SS\",\n",
    "    14: \"AV\",\n",
    "    15: \"GLOF\",\n",
    "    16: \"HW\",\n",
    "    17: \"CW\",\n",
    "    18: \"DI\",\n",
    "    19: \"OT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}{abbr_map.get(col[1], col[1])}\"\n",
    "    for col in df_wide.columns.to_flat_index()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "#### Section 07-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S07_1.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['G03YR', 'G04', 'G05', 'G06',\n",
    "       'G07', 'G08', 'G09', 'G10', 'G11', 'G12']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['DisasterFoodShortage_Dummy'] = np.where(df_read['G06'] == 'Yes', 1, 0)\n",
    "df_read['DisasterDie_Dummy'] = np.where(df_read['G07'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'G01CODE', 'DisasterFoodShortage_Dummy', 'DisasterDie_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"G01CODE\", \n",
    "           values=[\"DisasterFoodShortage_Dummy\", \"DisasterDie_Dummy\"])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    \"Drought\": \"DR\",\n",
    "    \"Fire (forest)\": \"FF\",\n",
    "    \"Fire (settlement)\": \"FS\",\n",
    "    \"Flood\": \"FL\",\n",
    "    \"Inundation\": \"IN\",\n",
    "    \"Windstorm\": \"WS\",\n",
    "    \"Thunderstorm\": \"TS\",\n",
    "    \"Hailstorm\": \"HS\",\n",
    "    \"Heavy rain\": \"HR\",\n",
    "    \"Sporadic rain\": \"SR\",\n",
    "    \"Soil erosion\": \"SE\",\n",
    "    \"Land slide\": \"LS\",\n",
    "    \"Snowstorm\": \"SS\",\n",
    "    \"Avalanche\": \"AV\",\n",
    "    \"GLOF\": \"GLOF\",\n",
    "    \"Heat wave\": \"HW\",\n",
    "    \"Cold wave\": \"CW\",\n",
    "    \"Diseases / insect\": \"DI\",\n",
    "    \"Others\": \"OT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}{abbr_map.get(col[1], col[1])}\"\n",
    "    for col in df_wide.columns.to_flat_index()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "176",
   "metadata": {},
   "source": [
    "#### Section 07-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S07_2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['G15YN']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['DisasterMoneyLoss_Dummy'] = np.where(df_read['G15YN'] == 'Yes', 1, 0)\n",
    "\n",
    "df_read['DisasterMoneyLoss_TotalNRs'] = np.nansum(df_read[['G16', 'G17', 'G18', 'G19', 'G20', 'G21', 'G22', 'G23']].fillna(0), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"G13CODE\", \n",
    "           values=[\"DisasterMoneyLoss_Dummy\", \"DisasterMoneyLoss_TotalNRs\"])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    \"Drought\": \"DR\",\n",
    "    \"Fire (forest)\": \"FF\",\n",
    "    \"Fire (settlement)\": \"FS\",\n",
    "    \"Flood\": \"FL\",\n",
    "    \"Inundation\": \"IN\",\n",
    "    \"Windstorm\": \"WS\",\n",
    "    \"Thunderstorm\": \"TS\",\n",
    "    \"Hailstorm\": \"HS\",\n",
    "    \"Heavy rain\": \"HR\",\n",
    "    \"Sporadic rain\": \"SR\",\n",
    "    \"Soil erosion\": \"SE\",\n",
    "    \"Land slide\": \"LS\",\n",
    "    \"Snowstorm\": \"SS\",\n",
    "    \"Avalanche\": \"AV\",\n",
    "    \"GLOF\": \"GLOF\",\n",
    "    \"Heat wave\": \"HW\",\n",
    "    \"Cold wave\": \"CW\",\n",
    "    \"Diseases / insect\": \"DI\",\n",
    "    \"Others\": \"OT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}{abbr_map.get(col[1], col[1])}\"\n",
    "    for col in df_wide.columns.to_flat_index()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "192",
   "metadata": {},
   "source": [
    "#### Section 08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193",
   "metadata": {},
   "source": [
    "Yes is Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S08.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['NewDiseaseCropPast25_Dummy'] = np.where(df_read['H01'] == 'Yes', 1, 0)\n",
    "df_read['NewInsectCropPast25_Dummy'] = np.where(df_read['H03'] == 'Yes', 1, 0)\n",
    "df_read['NewDiseaseLivestockPast25_Dummy'] = np.where(df_read['H05'] == 'Yes', 1, 0)\n",
    "\n",
    "df_read['HumanDiseaseIncreasePast25_Dummy'] = np.where(df_read['H07'] == 'Yes', 1, 0)\n",
    "df_read['HumanVetorDisIncreasePast25_Dummy'] = np.where(df_read['H09'] == 'Yes', 1, 0)\n",
    "df_read['HumanWaterDisIncreasePast25_Dummy'] = np.where(df_read['H10'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'NewDiseaseCropPast25_Dummy', 'NewInsectCropPast25_Dummy',\n",
    "       'NewDiseaseLivestockPast25_Dummy', 'HumanDiseaseIncreasePast25_Dummy',\n",
    "       'HumanVetorDisIncreasePast25_Dummy',\n",
    "       'HumanWaterDisIncreasePast25_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "203",
   "metadata": {},
   "source": [
    "#### Section 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S09.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['WaterSourceRiver_IncreaseDummy'] = np.where(df_read['I01'] == 1, 1, 0)\n",
    "df_read['WaterSourceRiver_DecreaseDummy'] = np.where(df_read['I01'] == 2, 1, 0)\n",
    "df_read['WaterSourceRiver_DeteriorationDummy'] = np.where(df_read['I02'] == 1, 1, 0)\n",
    "\n",
    "df_read['WaterSourceWell_IncreaseDummy'] = np.where(df_read['I03'] == 1, 1, 0)\n",
    "df_read['WaterSourceWell_DecreaseDummy'] = np.where(df_read['I03'] == 2, 1, 0)\n",
    "df_read['WaterSourceWell_DeteriorationDummy'] = np.where(df_read['I04'] == 1, 1, 0)\n",
    "\n",
    "df_read['WaterSourceRiver_DriedDummy'] = np.where(df_read['I05'] == 1, 1, 0)\n",
    "df_read['WaterSourceWell_DriedDummy'] = np.where(df_read['I07'] == 1, 1, 0)\n",
    "df_read['WaterSourceSpout_DriedDummy'] = np.where(df_read['I09'] == 1, 1, 0)\n",
    "\n",
    "df_read['WaterSourceSpout_IncreaseDummy'] = np.where(df_read['I08'] == 1, 1, 0)\n",
    "df_read['WaterSourceSpout_DecreaseDummy'] = np.where(df_read['I08'] == 2, 1, 0)\n",
    "\n",
    "df_read['WaterSourcePipe_IncreaseDummy'] = np.where(df_read['I10'] == 1, 1, 0)\n",
    "df_read['WaterSourcePipe_DecreaseDummy'] = np.where(df_read['I10'] == 2, 1, 0)\n",
    "\n",
    "df_read['WaterSourceChangePast25_Dummy'] = np.where(df_read['I11'] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'WaterSourceRiver_IncreaseDummy', 'WaterSourceRiver_DecreaseDummy',\n",
    "       'WaterSourceRiver_DeteriorationDummy', 'WaterSourceWell_IncreaseDummy',\n",
    "       'WaterSourceWell_DecreaseDummy', 'WaterSourceWell_DeteriorationDummy',\n",
    "       'WaterSourceRiver_DriedDummy', 'WaterSourceWell_DriedDummy',\n",
    "       'WaterSourceSpout_DriedDummy', 'WaterSourceSpout_IncreaseDummy',\n",
    "       'WaterSourceSpout_DecreaseDummy', 'WaterSourcePipe_IncreaseDummy',\n",
    "       'WaterSourcePipe_DecreaseDummy', 'WaterSourceChangePast25_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "214",
   "metadata": {},
   "source": [
    "#### Section 10-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S10_1.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['J03', 'J04', 'J05', 'J06', 'J07']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Drop_Dummy'] = np.where(df_read['J03'] == 'Changed', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'J01CODE', 'Drop_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"J01CODE\", \n",
    "           values=\"Drop_Dummy\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    \"Tree\": \"Tree\",\n",
    "    \"Shrub / bush\": \"Shrub\",\n",
    "    \"Herbal plant / non-timber forest product\": \"Herbal\",\n",
    "    \"Grass / Fodder\": \"Grass\",\n",
    "    \"Aquatic animal\": \"AquAnimal\",\n",
    "    \"Aquatic plant\": \"AquPlant\",\n",
    "    \"Wild animal\": \"WildAnimal\",\n",
    "    \"Birds\": \"Birds\",\n",
    "    \"Insects\": \"Insects\"\n",
    "}\n",
    "new_cols = []\n",
    "for c in df_wide.columns:\n",
    "    if c in [\"PSU\", \"HHLD\"]:\n",
    "        new_cols.append(c)\n",
    "    elif c in abbr_map:\n",
    "        new_cols.append(f\"{abbr_map[c]}_Drop_Dummy\")\n",
    "    else:\n",
    "        new_cols.append(c)\n",
    "df_wide.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_wide, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "229",
   "metadata": {},
   "source": [
    "#### Section 10-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S10_2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['J10YN', 'J11', 'J12', 'J13',\n",
    "       'J14A', 'J14B', 'J14C']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Invasion_Dummy'] = np.where(df_read['J10YN'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'J09TYPE', 'Invasion_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"J09TYPE\", \n",
    "           values=\"Invasion_Dummy\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    \"1. Shrub / bush\": \"Shrub\",\n",
    "    \"2. Climber\": \"Climber\",\n",
    "    \"3. Creeper\": \"Creeper\"\n",
    "}\n",
    "new_cols = []\n",
    "for c in df_wide.columns:\n",
    "    if c in [\"PSU\", \"HHLD\"]:\n",
    "        new_cols.append(c)\n",
    "    elif c in abbr_map:\n",
    "        new_cols.append(f\"{abbr_map[c]}_Invasion_Dummy\")\n",
    "    else:\n",
    "        new_cols.append(c)\n",
    "df_wide.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_wide, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "244",
   "metadata": {},
   "source": [
    "#### Section 10-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245",
   "metadata": {},
   "source": [
    "Yes is Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S10_3.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['J23']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['EarlyTree_Dummy', 'LaterTree_Dummy', 'EarlyShrub_Dummy', 'LaterShrub_Dummy',\n",
    "             'EarlyFruit_Dummy', 'LaterFruit_Dummy', 'EarlyHerb_Dummy', 'LaterHerb_Dummy']\n",
    "code_list = ['J15', 'J16', 'J17', 'J18', 'J19', 'J20', 'J21', 'J22']\n",
    "for name, code in zip(name_list, code_list):\n",
    "    df_read[name] = np.where(df_read[code] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['FruitSizeIncrease_Dummy'] = np.where(df_read['J23'] == '', 1, 0)\n",
    "df_read['FruitSizeDecrease_Dummy'] = np.where(df_read['J23'] == '', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'EarlyTree_Dummy', 'LaterTree_Dummy', 'EarlyShrub_Dummy',\n",
    "       'LaterShrub_Dummy', 'EarlyFruit_Dummy', 'LaterFruit_Dummy',\n",
    "       'EarlyHerb_Dummy', 'LaterHerb_Dummy', 'FruitSizeIncrease_Dummy',\n",
    "       'FruitSizeDecrease_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "259",
   "metadata": {},
   "source": [
    "#### Section 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S11.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read[['PSU', 'HHLD', 'K01']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['TouristImportance'] = (df_read['K01'] - 2).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'TouristImportance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "270",
   "metadata": {},
   "source": [
    "#### Section 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2016/Data/Data/S12.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in df_read.columns[2:]:\n",
    "    df_read[name] = np.where(df_read[name] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = ['PSU', 'HHLD', \n",
    "                   'SkillTrainingPast25', 'ChangeCropPatternPast25', 'LeftLandFallow', 'RearedLivestockPAst25', 'SuppIrrigationPast25',\n",
    "                   'InvestIrrigationPast25', 'ImprovedSeedPast25', 'ChangePlantingDatePast25', 'IncreaseInorganicFertilizersPAst25', 'IncreaseOrganicFertilizersPAst25',\n",
    "                   'NewCropsPast25', 'NewLivestockPast25', 'InvestLivestockPestPast25', 'InsuranceLivestockPast25', 'InsuranceCropPast25',\n",
    "                   'FarmingLivestockPast25', 'FarmingCropPast25', 'FarmingLivestockAndCropPast25', 'AgroForestPast25', 'CompatibleCropPast25',\n",
    "                   'TunnelFramingPast25', 'ColdStoragePast25', 'SeedBankPast25', 'SoilWaterConservationPast25', 'VisitClimateOfficePast25',\n",
    "                   'FoodConsumptionHabitPast25', 'OfffarmActiPast25', 'NonFarmEmployPast25', 'FamilyMigrationPast25', 'RiskReductionPast25',\n",
    "                   'RoadImprovementPast25', 'CommunityPartipationPast25'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "280",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.to_parquet('Data/01_Napel2016.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284",
   "metadata": {},
   "source": [
    "## DAtaset 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls \"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "287",
   "metadata": {},
   "source": [
    "### Data Merger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288",
   "metadata": {},
   "source": [
    "#### Section 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S01.dta\", \n",
    "                        convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['psu', 'hhld', 'respsex', 'respage', 'a14', 'a15']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = ['PSU', 'HHLD', \n",
    "                  'Respon_Female', 'Respon_Age', 'Edu', 'LivingYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.loc[:, 'Respon_Female'] = df_read.loc[:, 'Respon_Female'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read.assign(\n",
    "    Edu_UnderSLC     = np.where(df_read[\"Edu\"] < 12, 1, 0),\n",
    "    Edu_Certificate  = np.where(df_read[\"Edu\"] == 12, 1, 0),\n",
    "    Edu_Bachelor     = np.where(df_read[\"Edu\"] == 13, 1, 0),\n",
    "    Edu_Master       = np.where(df_read[\"Edu\"] == 14, 1, 0),\n",
    "    Edu_PhD          = np.where(df_read[\"Edu\"] == 15, 1, 0),\n",
    "    Edu_Literal      = np.where(df_read[\"Edu\"] == 16, 1, 0),\n",
    "    Edu_Illiterate   = np.where(df_read[\"Edu\"] == 17, 1, 0)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_year_map = {\n",
    "    1: 1,  2: 2,  3: 3,  4: 4,  5: 5,  6: 6,  7: 7,  8: 8,  9: 9, 10: 10, 11: 11,\n",
    "    12: 12,      # Certificate level\n",
    "    13: 16,      # Bachelor\n",
    "    14: 18,      # Master\n",
    "    15: 21,      # PhD\n",
    "    16: 0,       # Literal\n",
    "    17: 0        # Illiterate\n",
    "}\n",
    "\n",
    "df_read[\"Edu_year\"] = df_read[\"Edu\"].map(edu_year_map).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_read[['PSU', 'HHLD', 'Respon_Female',\n",
    "       'Respon_Age', 'LivingYear', 'Edu_UnderSLC', 'Edu_Certificate',\n",
    "       'Edu_Bachelor', 'Edu_Master', 'Edu_PhD', 'Edu_Literal',\n",
    "       'Edu_Illiterate', \"Edu_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "301",
   "metadata": {},
   "source": [
    "#### Section 02-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S02_1.dta\", convert_categoricals=False)\n",
    "df_read['PSU'] = df_read['psu']\n",
    "df_read['HHLD'] = df_read['hhld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Female_Ratio'] = df_read['b05sex'] - 1\n",
    "df_read['U18_Ratio'] = np.where(df_read[\"b06age\"] < 18, 1, 0)\n",
    "df_read['A65_Ratio'] = np.where(df_read[\"b06age\"] >= 65, 1, 0)\n",
    "\n",
    "df_read[\"B07EDU\"] = df_read[\"b07edu\"].fillna(17)\n",
    "df_read['Edu12_Ratio'] = np.where((df_read[\"b07edu\"] >= 12)&(df_read[\"b07edu\"] < 16), 1, 0)\n",
    "df_read['Literal_Ratio'] = np.where((df_read[\"b07edu\"] >= 12)&(df_read[\"b07edu\"] < 17), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'Female_Ratio', 'U18_Ratio', 'A65_Ratio',\n",
    "       'Edu12_Ratio', 'Literal_Ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_read.groupby(['PSU', 'HHLD']).count().reset_index()['b02sn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_ratio = df_select.groupby(['PSU', 'HHLD']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_ratio['Household_memberNum'] = df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select_ratio, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "316",
   "metadata": {},
   "source": [
    "#### Section 02-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S02_2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['B12A', 'B12B', 'B12C', 'B13A', 'B13B', 'B13C']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['TV', 'LANDLINEPHONE',\n",
    "       'ORDINRYMOBILE', 'SMARTMOBILE', 'COMPUTER', 'INTERNET', 'CARJEEP',\n",
    "       'ELECTRCVEHICL', 'MOTORCYCLE', 'ELECTRCBIKE', 'BICYCLE', 'ELECTRCFAN',\n",
    "       'REFRIGERATOR', 'WASHINGMACHINE', 'AIRCONDITNR', 'NOFACILITY']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S02_2.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['TV', 'LANDLINEPHONE',\n",
    "       'ORDINRYMOBILE', 'SMARTMOBILE', 'COMPUTER', 'INTERNET', 'CARJEEP',\n",
    "       'ELECTRCVEHICL', 'MOTORCYCLE', 'ELECTRCBIKE', 'BICYCLE', 'ELECTRCFAN',\n",
    "       'REFRIGERATOR', 'WASHINGMACHINE', 'AIRCONDITNR', 'NOFACILITY']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read[\"Radio_dummy\"] = df_read[\"RADIO\"]\n",
    "df_read[\"TV_dummy\"] = df_read[\"TV\"]\n",
    "df_read[\"PC_dummy\"] = df_read[\"COMPUTER\"]\n",
    "df_read[\"Net_dummy\"] = df_read[\"INTERNET\"]\n",
    "df_read[\"Phone_dummy\"] = df_read[\"LANDLINEPHONE\"]\n",
    "df_read[\"Mobile_dummy\"] = ((df_read[\"ORDINRYMOBILE\"] == 1) | (df_read[\"SMARTMOBILE\"] == 1)).astype(int)\n",
    "df_read[\"Motorbike_dummy\"] = df_read[\"MOTORCYCLE\"]\n",
    "df_read[\"Car_dummy\"] = df_read[\"CARJEEP\"]\n",
    "df_read[\"Bike_dummy\"] = df_read[\"BICYCLE\"]\n",
    "df_read[\"OtherVehi_dummy\"] = df_read[\"ELECTRCBIKE\"]\n",
    "df_read[\"Refrige_dummy\"] = df_read[\"REFRIGERATOR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'B10', 'B11', 'B12A', 'B12B',\n",
    "        'B12C', 'B13A', 'B13B', 'B13C', 'B14', 'B15', 'B16A', 'B16B', 'B16C',\n",
    "         'B18', 'C01', 'C02', 'Radio_dummy', 'TV_dummy',\n",
    "       'PC_dummy', 'Net_dummy', 'Phone_dummy', 'Mobile_dummy',\n",
    "       'Motorbike_dummy', 'Car_dummy', 'Bike_dummy', 'OtherVehi_dummy',\n",
    "       'Refrige_dummy']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.columns = ['PSU', 'HHLD', 'Own_Resid', 'Resid_Type', 'WaterS1', 'WaterS2',\n",
    "        'WaterS3', 'CookFuelS1', 'CookFuelS2', 'CookFuelS3', 'LightEnergy', 'Toilet', 'IncomeS1', 'IncomeS2', 'IncomeS3',\n",
    "         'Remittance_dummy', 'Have_AgriLand', 'HouseHead_AgriExpYear', 'Radio_dummy',\n",
    "       'TV_dummy', 'PC_dummy', 'Net_dummy', 'Phone_dummy', 'Mobile_dummy',\n",
    "       'Motorbike_dummy', 'Car_dummy', 'Bike_dummy', 'OtherVehi_dummy',\n",
    "       'Refrige_dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select['Remittance_dummy'] = (df_select['Remittance_dummy'] - 2).abs()\n",
    "df_select['Have_AgriLand'] = (df_select['Have_AgriLand'] - 2).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "337",
   "metadata": {},
   "source": [
    "#### Section 04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338",
   "metadata": {},
   "source": [
    "**Yes is Yes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S04.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['SavingMembership'] = np.where(df_read[\"D01\"] == 1, 1, 0)\n",
    "df_read['RegularSaving'] = np.where(df_read[\"D02\"] == 1, 1, 0)\n",
    "df_read['OrgMembership'] = np.where(df_read[\"D07\"] == 1, 1, 0)\n",
    "df_read['AgriSupport'] = np.where(df_read[\"D10\"] == 1, 1, 0)\n",
    "df_read['Dist_Road'] = df_read[\"D12\"]\n",
    "df_read['Dist_HealthCenter'] = df_read[\"D13\"]\n",
    "df_read['Dist_SecondarySchool'] = df_read[\"D14\"]\n",
    "df_read['Dist_Market'] = df_read[\"D15\"]\n",
    "df_read['Dist_AgriSupport'] = df_read[\"D16\"]\n",
    "df_read['FramMechan'] = np.where(df_read[\"D17\"] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'SavingMembership',\n",
    "       'RegularSaving', 'OrgMembership', 'AgriSupport', 'Dist_Road',\n",
    "       'Dist_HealthCenter', 'Dist_SecondarySchool', 'Dist_Market',\n",
    "       'Dist_AgriSupport', 'FramMechan']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_select.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "350",
   "metadata": {},
   "source": [
    "#### Section 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S05.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['TotalIncome'] = df_read[['E01', 'E02', 'E03', 'E04']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = ['PSU', 'HHLD', 'CropIncome', 'LivestockIncome', 'NonAgriIncome', 'BusiIncome', 'TotalIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362",
   "metadata": {},
   "source": [
    "#### Section 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S06.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['HeardClimate_Dummy'] = np.where(df_read['F01'] == 'Yes', 1, 0)\n",
    "df_read['ClimateChanged_Dummy'] = np.where(df_read['F03'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369",
   "metadata": {},
   "outputs": [],
   "source": [
    "f02_dummies = pd.get_dummies(df_read[\"F02\"], prefix=\"ClimateInfo\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370",
   "metadata": {},
   "outputs": [],
   "source": [
    "f02_dummies.columns = [name[:17] for name in f02_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371",
   "metadata": {},
   "outputs": [],
   "source": [
    "f02_dummies = f02_dummies[['ClimateInfo_Radio',\n",
    "       'ClimateInfo_Telev', 'ClimateInfo_News ', 'ClimateInfo_Aware',\n",
    "       'ClimateInfo_Local', 'ClimateInfo_Neigh', 'ClimateInfo_Famil',\n",
    "       'ClimateInfo_Other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f02_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04a_dummies = pd.get_dummies(df_read[\"F04A\"], prefix=\"ClimateReasonA\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04a_dummies.columns = [name[:20] for name in f04a_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04a_dummies = f04a_dummies[['ClimateReasonA_Defor', 'ClimateReasonA_Natur',\n",
    "       'ClimateReasonA_Indus', 'ClimateReasonA_Urban', 'ClimateReasonA_Human',\n",
    "       'ClimateReasonA_God\\'s', 'ClimateReasonA_Earth', 'ClimateReasonA_Other',\n",
    "       'ClimateReasonA_Don\\'t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f04a_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04b_dummies = pd.get_dummies(df_read[\"F04B\"], prefix=\"ClimateReasonB\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04b_dummies.columns = [name[:20] for name in f04b_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04b_dummies = f04b_dummies[['ClimateReasonB_Defor', 'ClimateReasonB_Natur',\n",
    "       'ClimateReasonB_Indus', 'ClimateReasonB_Urban', 'ClimateReasonB_Human',\n",
    "       'ClimateReasonB_God\\'s', 'ClimateReasonB_Earth', 'ClimateReasonB_Other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f04b_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04c_dummies = pd.get_dummies(df_read[\"F04C\"], prefix=\"ClimateReasonC\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04c_dummies.columns = [name[:20] for name in f04c_dummies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383",
   "metadata": {},
   "outputs": [],
   "source": [
    "f04c_dummies = f04c_dummies[['ClimateReasonC_Defor', 'ClimateReasonC_Natur', 'ClimateReasonC_Indus',\n",
    "       'ClimateReasonC_Urban', 'ClimateReasonC_Human', 'ClimateReasonC_God\\'s',\n",
    "       'ClimateReasonC_Earth', 'ClimateReasonC_Other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.concat([df_read, f04c_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.replace( '\\'' ,'x') for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'HeardClimate_Dummy', 'ClimateChanged_Dummy', 'ClimateInfo_Radio',\n",
    "       'ClimateInfo_Telev', 'ClimateInfo_News ', 'ClimateInfo_Aware',\n",
    "       'ClimateInfo_Local', 'ClimateInfo_Neigh', 'ClimateInfo_Famil',\n",
    "       'ClimateInfo_Other', 'ClimateReasonA_Defor', 'ClimateReasonA_Natur',\n",
    "       'ClimateReasonA_Indus', 'ClimateReasonA_Urban', 'ClimateReasonA_Human',\n",
    "       'ClimateReasonA_Godxs', 'ClimateReasonA_Earth', 'ClimateReasonA_Other',\n",
    "       'ClimateReasonA_Donxt', 'ClimateReasonB_Defor', 'ClimateReasonB_Natur',\n",
    "       'ClimateReasonB_Indus', 'ClimateReasonB_Urban', 'ClimateReasonB_Human',\n",
    "       'ClimateReasonB_Godxs', 'ClimateReasonB_Earth', 'ClimateReasonB_Other',\n",
    "       'ClimateReasonC_Defor', 'ClimateReasonC_Natur', 'ClimateReasonC_Indus',\n",
    "       'ClimateReasonC_Urban', 'ClimateReasonC_Human', 'ClimateReasonC_Godxs',\n",
    "       'ClimateReasonC_Earth', 'ClimateReasonC_Other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391",
   "metadata": {},
   "source": [
    "#### Section 06-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S06_3.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['ExpDummy'] = np.where(df_read['F17'] == 1, 1, 0)\n",
    "df_read['Impact'] = df_read['F18'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"F15SN\", \n",
    "           values=[\"ExpDummy\", 'Impact'])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    1: \"DR\",\n",
    "    2: \"FF\",\n",
    "    3: \"FS\",\n",
    "    4: \"FL\",\n",
    "    5: \"IN\",\n",
    "    6: \"WS\",\n",
    "    7 :\"TS\",\n",
    "    8: \"HS\",\n",
    "    9: \"HR\",\n",
    "    10: \"SR\",\n",
    "    11: \"SE\",\n",
    "    12: \"LS\",\n",
    "    13: \"SS\",\n",
    "    14: \"AV\",\n",
    "    15: \"GLOF\",\n",
    "    16: \"HW\",\n",
    "    17: \"CW\",\n",
    "    18: \"DI\",\n",
    "    19: \"OT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}{abbr_map.get(col[1], col[1])}\"\n",
    "    for col in df_wide.columns.to_flat_index()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406",
   "metadata": {},
   "source": [
    "#### Section 07-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S07_1.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['G03YR', 'G04', 'G05', 'G06',\n",
    "       'G07', 'G08', 'G09', 'G10', 'G11', 'G12']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['DisasterFoodShortage_Dummy'] = np.where(df_read['G06'] == 1, 1, 0)\n",
    "df_read['DisasterDie_Dummy'] = np.where(df_read['G07'] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'G01SN', 'DisasterFoodShortage_Dummy', 'DisasterDie_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"G01SN\", \n",
    "           values=[\"DisasterFoodShortage_Dummy\", \"DisasterDie_Dummy\"])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    1: \"DR\",\n",
    "    2: \"FF\",\n",
    "    3: \"FS\",\n",
    "    4: \"FL\",\n",
    "    5: \"IN\",\n",
    "    6: \"WS\",\n",
    "    7 :\"TS\",\n",
    "    8: \"HS\",\n",
    "    9: \"HR\",\n",
    "    10: \"SR\",\n",
    "    11: \"SE\",\n",
    "    12: \"LS\",\n",
    "    13: \"SS\",\n",
    "    14: \"AV\",\n",
    "    15: \"GLOF\",\n",
    "    16: \"HW\",\n",
    "    17: \"CW\",\n",
    "    18: \"DI\",\n",
    "    19: \"OT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}{abbr_map.get(col[1], col[1])}\"\n",
    "    for col in df_wide.columns.to_flat_index()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "424",
   "metadata": {},
   "source": [
    "#### Section 07-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S07_2.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['G15SN']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['DisasterMoneyLoss_Dummy'] = np.where(df_read['G17YN'] == 'Yes', 1, 0)\n",
    "\n",
    "df_read['DisasterMoneyLoss_TotalNRs'] = df_read['G18'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"G15SN\", \n",
    "           values=[\"DisasterMoneyLoss_Dummy\", \"DisasterMoneyLoss_TotalNRs\"])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    1: \"DR\",\n",
    "    2: \"FF\",\n",
    "    3: \"FS\",\n",
    "    4: \"FL\",\n",
    "    5: \"IN\",\n",
    "    6: \"WS\",\n",
    "    7 :\"TS\",\n",
    "    8: \"HS\",\n",
    "    9: \"HR\",\n",
    "    10: \"SR\",\n",
    "    11: \"SE\",\n",
    "    12: \"LS\",\n",
    "    13: \"SS\",\n",
    "    14: \"AV\",\n",
    "    15: \"GLOF\",\n",
    "    16: \"HW\",\n",
    "    17: \"CW\",\n",
    "    18: \"DI\",\n",
    "    19: \"OT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}{abbr_map.get(col[1], col[1])}\"\n",
    "    for col in df_wide.columns.to_flat_index()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439",
   "metadata": {},
   "source": [
    "#### Section 08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440",
   "metadata": {},
   "source": [
    "Yes is Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S08.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['NewDiseaseCropPast25_Dummy'] = np.where(df_read['H01'] == 'Yes', 1, 0)\n",
    "df_read['NewInsectCropPast25_Dummy'] = np.where(df_read['H03'] == 'Yes', 1, 0)\n",
    "df_read['NewDiseaseLivestockPast25_Dummy'] = np.where(df_read['H05'] == 'Yes', 1, 0)\n",
    "\n",
    "df_read['HumanDiseaseIncreasePast25_Dummy'] = np.where(df_read['H07'] == 'Yes', 1, 0)\n",
    "df_read['HumanVetorDisIncreasePast25_Dummy'] = np.where(df_read['H09'] == 'Yes', 1, 0)\n",
    "df_read['HumanWaterDisIncreasePast25_Dummy'] = np.where(df_read['H10'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'NewDiseaseCropPast25_Dummy', 'NewInsectCropPast25_Dummy',\n",
    "       'NewDiseaseLivestockPast25_Dummy', 'HumanDiseaseIncreasePast25_Dummy',\n",
    "       'HumanVetorDisIncreasePast25_Dummy',\n",
    "       'HumanWaterDisIncreasePast25_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "451",
   "metadata": {},
   "source": [
    "#### Section 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S09.dta\",\n",
    "                       convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['WaterSourceRiver_IncreaseDummy'] = np.where(df_read['I05'] == 1, 1, 0)\n",
    "df_read['WaterSourceRiver_DecreaseDummy'] = np.where(df_read['I05'] == 2, 1, 0)\n",
    "\n",
    "\n",
    "df_read['WaterSourceRiver_DriedDummy'] = np.where(df_read['I06'] == 1, 1, 0)\n",
    "\n",
    "df_read['WaterSourceSpout_IncreaseDummy'] = np.where(df_read['I03'] == 1, 1, 0)\n",
    "df_read['WaterSourceSpout_DecreaseDummy'] = np.where(df_read['I03'] == 2, 1, 0)\n",
    "\n",
    "df_read['WaterSourcePipe_IncreaseDummy'] = np.where(df_read['I07'] == 1, 1, 0)\n",
    "df_read['WaterSourcePipe_DecreaseDummy'] = np.where(df_read['I07'] == 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'WaterSourceRiver_IncreaseDummy',\n",
    "       'WaterSourceRiver_DecreaseDummy', 'WaterSourceRiver_DriedDummy',\n",
    "       'WaterSourceSpout_IncreaseDummy', 'WaterSourceSpout_DecreaseDummy',\n",
    "       'WaterSourcePipe_IncreaseDummy', 'WaterSourcePipe_DecreaseDummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463",
   "metadata": {},
   "source": [
    "#### Section 10-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S10_1.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['J03']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Drop_Dummy'] = np.where(df_read['J03'] == 'Changed', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'J01SN', 'Drop_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"J01SN\", \n",
    "           values=\"Drop_Dummy\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    \"Tree\": \"Tree\",\n",
    "    \"Shrub\": \"Shrub\",\n",
    "    \"Herbal plant / non-timber forest product\": \"Herbal\",\n",
    "    \"Grass / fodder\": \"Grass\",\n",
    "    \"Aquatic animal\": \"AquAnimal\",\n",
    "    \"Aquatic plant\": \"AquPlant\",\n",
    "    \"Wild animal\": \"WildAnimal\",\n",
    "    \"Birds\": \"Birds\",\n",
    "    \"Insects\": \"Insects\"\n",
    "}\n",
    "new_cols = []\n",
    "for c in df_wide.columns:\n",
    "    if c in [\"PSU\", \"HHLD\"]:\n",
    "        new_cols.append(c)\n",
    "    elif c in abbr_map:\n",
    "        new_cols.append(f\"{abbr_map[c]}_Drop_Dummy\")\n",
    "    else:\n",
    "        new_cols.append(c)\n",
    "df_wide.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_wide, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "479",
   "metadata": {},
   "source": [
    "#### Section 10-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S10_2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['J10SN', 'J12YN']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Invasion_Dummy'] = np.where(df_read['J12YN'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'J10SN', 'Invasion_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_read\n",
    "    .pivot(index=[\"PSU\", \"HHLD\"], \n",
    "           columns=\"J10SN\", \n",
    "           values=\"Invasion_Dummy\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_map = {\n",
    "    \"Shrub\": \"Shrub\",\n",
    "    \"Climber plant climb on Tree\": \"Climber\",\n",
    "    \"Creeper plant on land\": \"Creeper\"\n",
    "}\n",
    "new_cols = []\n",
    "for c in df_wide.columns:\n",
    "    if c in [\"PSU\", \"HHLD\"]:\n",
    "        new_cols.append(c)\n",
    "    elif c in abbr_map:\n",
    "        new_cols.append(f\"{abbr_map[c]}_Invasion_Dummy\")\n",
    "    else:\n",
    "        new_cols.append(c)\n",
    "df_wide.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df_wide[['PSU', 'HHLD', 'Shrub_Invasion_Dummy', 'Climber_Invasion_Dummy',\n",
    "       'Creeper_Invasion_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_wide, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497",
   "metadata": {},
   "source": [
    "#### Section 10-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498",
   "metadata": {},
   "source": [
    "Yes is Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S10_3.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical summaries\n",
    "for col in ['J23']:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_read[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['EarlyTree_Dummy', 'LaterTree_Dummy', 'EarlyShrub_Dummy', 'LaterShrub_Dummy',\n",
    "             'EarlyFruit_Dummy', 'LaterFruit_Dummy', 'EarlyHerb_Dummy', 'LaterHerb_Dummy']\n",
    "code_list = ['J18', 'J19', 'J20', 'J21', 'J22', 'J23', 'J24', 'J25']\n",
    "for name, code in zip(name_list, code_list):\n",
    "    df_read[name] = np.where(df_read[code] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'EarlyTree_Dummy', 'LaterTree_Dummy', 'EarlyShrub_Dummy',\n",
    "       'LaterShrub_Dummy', 'EarlyFruit_Dummy', 'LaterFruit_Dummy',\n",
    "       'EarlyHerb_Dummy', 'LaterHerb_Dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "510",
   "metadata": {},
   "source": [
    "#### Section 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/S11.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = [name.upper() for name in df_read.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in df_read.columns[2:]:\n",
    "    df_read[name] = np.where(df_read[name] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = df_read[['PSU', 'HHLD', 'K01', 'K02', 'K03', 'K04', 'K05', \n",
    "                   'K06', 'K07', 'K08', 'K09', 'K10',\n",
    "                  'K12', 'K13', 'K14', 'K16', 'K19',\n",
    "                  'K22', 'K23', 'K24', 'K25', 'K26',\n",
    "                  'K28', 'K30', 'K31', 'K32',\n",
    "                  'K38', 'K39', 'K40', 'K41', 'K42',\n",
    "                  'K43', 'K44']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns = ['PSU', 'HHLD', \n",
    "                   'SkillTrainingPast25', 'ChangeCropPatternPast25', 'LeftLandFallow', 'RearedLivestockPAst25', 'SuppIrrigationPast25',\n",
    "                   'InvestIrrigationPast25', 'ImprovedSeedPast25', 'ChangePlantingDatePast25', 'IncreaseInorganicFertilizersPAst25', 'IncreaseOrganicFertilizersPAst25',\n",
    "                   'NewCropsPast25', 'NewLivestockPast25', 'InvestLivestockPestPast25', 'InsuranceLivestockPast25', 'InsuranceCropPast25',\n",
    "                   'FarmingLivestockPast25', 'FarmingCropPast25', 'FarmingLivestockAndCropPast25', 'AgroForestPast25', 'CompatibleCropPast25',\n",
    "                   'TunnelFramingPast25', 'ColdStoragePast25', 'SoilWaterConservationPast25', 'VisitClimateOfficePast25',\n",
    "                   'FoodConsumptionHabitPast25', 'OfffarmActiPast25', 'NonFarmEmployPast25', 'FamilyMigrationPast25', 'RiskReductionPast25',\n",
    "                   'RoadImprovementPast25', 'CommunityPartipationPast25'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "525",
   "metadata": {},
   "source": [
    "#### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_stata(\"PrivateData/Climate-2022/Data 2022/NCCS 2022/Data/Weight.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Rural_Dummy'] = np.where(df_read['UrbRur'] == 'Rural', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['Prov'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_read[['PSU', 'HHLD', 'Rural_Dummy', 'EcoBelt', 'Prov']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df_kept.merge(df_select, on = ['PSU', 'HHLD'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "537",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept.to_parquet('Data/01_Napel2022.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
